# AIに攻略本を作らせたい！ Wikipediaゴルフ編

## はじめに

この本では、「ゲームの攻略本をAI（大規模言語モデル; LLM）に自動で書かせる」という、少し風変わりな試みを紹介する。  
具体的には、Wikipediaゴルフというゲームを題材に、LLMにゲームをプレイさせ、そのプレイ経験をもとに攻略本を少しずつ改訂させていく仕組みを作った。その結果として得られた攻略本の例や、どの程度うまくいったのかという定量評価もあわせて報告する。

ここでいう「攻略本」とは、人間が読んで理解できる日本語テキストであり、ゲームをうまく進めるためのコツや考え方が整理されたものを指す。AlphaGoのような強力なゲームAIは、すでに多くのゲームで人間を上回る実力を示しているが、その内部は大量の数値からなるニューラルネットワークであり、どのような「考え」で一手を選んでいるのかを人間が直接読み解くことは難しい。本書で目指すのは、そうした「ブラックボックスとして強いAI」ではなく、「人間に説明可能な形でテクニックを教えてくれるAI」である。

そのための題材として、Wikipediaゴルフは非常に相性がよい。ゲームの状態が「ページ名」と「リンクの一覧」というテキストだけで表現でき、LLMが得意とする言語処理と親和性が高いからだ。一方で、オセロや将棋などの盤上ゲームでは、LLMは盤面を直接読んで強くなることが苦手であり、結局は人間が書いた定石や戦術記事を学習して再構成する以上のことはやりにくい。本書では、Wikipediaゴルフという「言葉で遊ぶゲーム」を通して、LLMがどこまで自律的に攻略本を作れるのかを探る。

本書の想定読者は、LLMやChatGPTといった技術に興味があり、自分でも何か面白い実験をしてみたいと考えているエンジニアや研究者、あるいは単に「AIに攻略本を書かせる」という発想にワクワクする読者である。PythonとAPIを使った実装の概要にも触れるが、コードの詳細よりも「全体の仕組み」と「得られた知見」に力点を置いて解説する。

## 攻略本をAIに書かせるとは何か

まず、本書で扱う「攻略本」の定義を整理しておく。ここでいう攻略本とは、次のような条件を満たすテキストである。

- ゲームのプレイに役立つ、具体的かつ一般化されたテクニックが書かれている  
- 日本語で書かれており、人間の読者が単体で読んでも意味が通る  
- 文字数は概ね2000文字以下で、短いながらも実用的な内容になっている

既存のゲームAI研究では、「うまくプレイできるかどうか」が主な評価軸となる。AlphaGoに代表される囲碁AIは、人間のトッププロを凌駕するが、内部の重みを眺めても、そこから「布石の基本はこう考えるべきだ」といった解説がそのまま出てくるわけではない。一方、人間向けの攻略本は、ゲームのルールや戦略を「言葉による説明」と「例示」によって伝えることを目的としている。

LLMは、このギャップを埋めるためのツールとして適している。プレイのログや対話履歴を渡して「このゲームをうまく遊ぶコツをまとめてください」と依頼すれば、ある程度筋の通った攻略本らしき文章を生成してくれる。本書の主眼は、このプロセスを一度きりで終わらせるのではなく、「ゲームをプレイする → 結果を踏まえて攻略本を改訂する」というサイクルを何度も回すことで、攻略本の質を自動的に高められるかどうかを検証する点にある。

## Wikipediaゴルフという題材

### Wikipediaゴルフのルール

Wikipediaゴルフは、オンライン百科事典Wikipedia上で遊ぶ一人用ゲームである。公式の説明では、次のように定義されている。

> プレイヤーはWikipediaのある記事からスタートし、ゴールとなる記事になるべく少ないウィキリンクのクリック数または速い時間で移動することを目指します。記事はおまかせ表示で選ぶか、指定されたものを使います。

本書で扱うシステムでは、このアイデアをもとに、LLMがプレイヤーとなって自動でWikipediaゴルフを遊ぶようにルールを整備した。主なルールは次の通りである。

- スタートとゴールのページは、日本語版Wikipedia全体からランダムに選ぶ  
- ただしゴールは、被リンク数が一定以上（実装では閾値を設定）あるページに限定する  
- 各ターンでできる行動は、「現在のページに含まれるリンクから1つを選んで移動」するか、「過去に訪れたページに戻る」ことだけ  
- 手数には上限があり、決められた回数（実装では最大20手）以内にゴールに到達できなければ失敗  
- LLMにはページ本文そのものは見せず、「現在地のページ名」と「リンク先ページ名の一覧」だけを渡す

人間がブラウザで遊ぶWikipediaゴルフとは少し異なり、本システムではページ本文の情報がないため、「リンクの名前」だけを手がかりにゴールに近づく必要がある。これは、LLMにとってもそれなりに難しいパズルであり、同じスタート・ゴールの組み合わせでも、プレイごとに異なるルートを辿ることがある。

### なぜWikipediaゴルフなのか

LLMを使って攻略本を自動生成する題材として、Wikipediaゴルフを選んだ理由は大きく二つある。

第一に、ゲームの状態がテキストだけで完結している点である。スタートとゴールのページ名、現在のページ名、リンク先の候補一覧といった情報は、すべて文字列として表現できる。これらをそのままLLMへのプロンプトに埋め込めばよく、追加の前処理や特殊な表現はほとんど必要ない。

第二に、LLMが比較的得意とする「知識の連想」や「概念の階層構造の理解」がそのまま攻略に直結する点である。例えば、「地方のテレビ中継局」から「国道のバイパス」にたどり着くには、地名や行政区画のページを経由して、道路に関するページに出ていく、といった連想が必要になる。これは、一般的なウェブテキストから学習したLLMが得意とする領域だ。

一方、オセロや将棋といったボードゲームでは、盤面を直接テキスト化しても、その構造をLLMが深く理解するのは簡単ではない。そうしたゲームに対するLLMの強さは、多くの場合、人間が書いた定石や解説記事を学習した結果として現れるに過ぎず、「プレイ経験から自ら戦略を言語化する」という面は弱い。Wikipediaゴルフは、この点でLLMの能力と目的がうまく噛み合う題材と言える。

## LLMにゲームをプレイさせる仕組み

では実際に、どのようにしてLLMにWikipediaゴルフをプレイさせているのか。本書で用いたシステムでは、Pythonで実装したゲームランナーがLLMと対話しながらゲームを進行する。ざっくりとした流れは次の通りである。

1. ゲームランナーがWikipedia APIを使ってスタートとゴールのページをランダムに選ぶ  
2. スタートページのリンク一覧を取得し、現在地・履歴・ターン数などの情報とあわせてLLMにプロンプトとして渡す  
3. LLMは内部で思考過程を文章として出力し、最後の行で「移動先: ○○○」という形式で次に移動するページ名を指定する  
4. ゲームランナーはその指定を検証し、実際にページを移動して履歴に記録する  
5. ゴールに到達すれば成功、手数上限に達するか不正な応答が続いた場合は失敗としてゲームを終了する

プレイ中、LLMが利用できる情報は「ページ名」と「リンク先ページ名の一覧」のみである。リンク先が500件以上あるページの場合は、その中からランダムに一部だけを選んで提示する。さらに、ページ名に数字（半角・全角問わず）が含まれるリンクは候補から除外されるようにした。これは、日付や年号、話数など数字を含むリンクをたどると、時間やエピソードの羅列ページに迷い込みやすく、ルート探索が難しくなるためである。

プロンプトの構造は、冒頭でルールと攻略本のテキストを示し、その後に現在の状況（スタート・ゴール・履歴・候補リンクなど）を列挙する形になっている。LLMには「最終行だけを『移動先: 候補名』の形式で出力すること」というルールを与え、そこから次の一手を抽出する。初回ターンのみ攻略本全文を提示し、2ターン目以降は現在の状況だけを渡すことで、トークン消費を抑えている。

## 攻略本を自動的に改善する

LLMとゲームランナーを組み合わせれば、手動でChatGPTを操作しなくても、自動的にWikipediaゴルフを何度もプレイさせることができる。ここから一歩進めて、「プレイ経験をもとに攻略本を自動で改訂させる」という仕組みを組み込んだ。

流れは次のようになる。

1. まず、LLMに「Wikipediaゴルフの攻略本を作ってください」と依頼し、初版の攻略本（バージョン0）を生成する  
2. この攻略本をゲームランナーに読み込ませ、Wikipediaゴルフを1プレイ実行する  
3. プレイ中の対話履歴や移動履歴、成功・失敗の結果をまとめてLLMに渡し、「この結果を踏まえて攻略本を改善してください」と依頼する  
4. LLMが出力した新しい攻略本を保存し、次のプレイではその最新版を使う  
5. 上記のサイクルを、所定の回数（実験では100回）繰り返す

このループを回すことで、攻略本はプレイの経験を少しずつ反映しながら改訂されていく。例えば、特定のルートで何度も行き詰まった場合、その原因となった選択の傾向をLLMが読み取り、「数字を含むリンクは基本的に避ける」「一覧ページを早めに踏む」といった指針として言語化してくれることが期待できる。

実装上は、攻略本の長さを1000文字程度に制限し、特定の実験回に依存する固有名詞や「このプレイでは〜」といった表現を避けるようにプロンプトで指示している。これにより、どのスタート・ゴールの組み合わせに対しても適用できる、汎用的なテクニック集としての性質を保つことを目指した。

## 実験設定

本書で報告する実験では、LLMとしてGoogleのGemini系モデルを利用した。トークン単価とスループットのバランスを考慮し、主に「gemini-2.5-flash-lite」相当のモデルを用いている。1プレイあたりおおよそ十数回のAPI呼び出しが発生するため、無料枠だけで長時間の実験を回すのは難しい。そこで、OpenRouterという仲介サービスを利用し、GeminiやGPTなどのモデルを共通のインターフェースから呼び出せるようにした。

攻略本の改善サイクルを評価するため、以下のような手順で実験を行った。

- まず、日本語版Wikipediaを対象に、スタートとゴールのペアをランダムに100組用意する  
- 初版の攻略本（バージョン0）を用いて、それぞれのペアについてWikipediaゴルフをプレイさせる  
- 次に、Wikipediaゴルフのプレイと攻略本改訂のサイクルを100回回し、その時点での最新版攻略本（バージョン100）を取得する  
- 同じ100組のスタート・ゴールペアについて、改訂版の攻略本を用いて再度プレイさせる  
- 各ペアについて「成功したかどうか」と「到達までの手数」を記録し、初版と改訂版のスコアを比較する

同様の実験を、MediaWikiを採用している他のサイトでも行った。具体的には、ポケモンに特化した「ポケモンWiki」と、旅行情報に特化した「Wikitravel」である。これらのサイトはWikipediaに比べてページ数が少ないため、ゴールとなるページの条件（被リンク数の下限）はやや緩めに設定した。

評価の際には、攻略本の生成は行わず、あくまで既に用意されたバージョン（例: 0, 100）を固定してゲームをプレイさせるだけにした。こうすることで、「攻略本の内容そのものが変化したこと」による影響を切り分けて比較しやすくなる。

## 実験結果

### Wikipediaでの結果

まず、日本語版Wikipediaでの結果を見てみよう。スタートとゴールのペア100組に対して、初版の攻略本と、100回の改訂を経た攻略本とでプレイを行ったところ、おおまかに次のような傾向が見られた。

- 初版攻略本での成功率はおよそ4割台前半  
- 改訂版攻略本での成功率はそれより数ポイント高く、4割台後半に達した  
- 到達したケースについての平均手数に大きな差は見られなかった

成功率の差は統計的に有意と言い切れるほど大きくはないものの、少なくとも「改訂を重ねた結果、元より明らかに悪くなった」ということはなかった。Wikipediaゴルフに関しては、LLMが学習段階で既にインターネット上の攻略記事やテクニックを読んでいると考えられるため、初版の時点である程度洗練された内容が出てきており、そこからの伸びしろはそれほど大きくなかったのかもしれない。

### ポケモンWikiとWikitravelでの結果

次に、ポケモンWikiとWikitravelでの結果を見てみる。いずれもMediaWikiを採用しており、リンク構造やAPIの扱いはWikipediaとほぼ同じだが、扱われているトピックが特化している点が異なる。

ポケモンWikiでは、ゴールページの条件を「被リンク数が10以上」と緩めに設定し、Wikipediaと同様に攻略本の改訂サイクルを回した。その結果、

- 初版攻略本での成功率は5割台半ば  
- 改訂版攻略本では6割台前半まで成功率が向上

という改善が見られた。ポケモンWikiの最終版攻略本には、  
「ページ名の末尾に付く『(GO)』『(アニメ)』『(カードゲーム)』といった表記は、ゴールページの種類を見極めるうえで重要である」  
といった、ポケモンWiki特有の記法に踏み込んだテクニックが含まれている。これは、実際にプレイを重ねる中でLLMがそのルール性に気づき、それを言語化した例と考えられる。

Wikitravelでは、もともとの成功率が高めであり、初版の時点で8割程度の成功率が出ていた。改訂版ではそれがさらに数ポイント向上し、8割台後半に達した。こちらも有意差とまでは言いにくいが、「プレイを通じて攻略本を更新しても性能が損なわれず、むしろわずかに改善する」という傾向が確認できた。

### コストと制約

これらの実験では、攻略本の改訂100回に加え、評価用のプレイを含めると合計で数百回のゲームプレイが必要になった。1プレイあたり数十回のAPI呼び出しが発生するため、モデル選択と呼び出し回数の制御には注意が必要である。

本書で扱った規模（数百プレイ）であれば、比較的安価なモデルを用いることで、総コストはおよそ数ドル程度に収まる。より高性能なモデルを使えば攻略本の質やプレイ精度が向上する可能性はあるが、その分コストも増大する。今後、大規模な実験を行う場合には、モデル選択やサンプリング戦略を工夫して「どの程度のコストで、どの程度の攻略本改善が見込めるか」を設計する必要がある。

## 実際に生成された攻略本

ここで、実際にシステムが生成した攻略本の一部を紹介する。いずれも、LLMが自動で生成・改訂したテキストであり、必要最小限の整形だけを行っている。

まず、日本語版Wikipediaを対象としたWikipediaゴルフの攻略本である。初版と改訂版の両方を比較すると、構成や表現は似ているものの、後者の方が若干抽象度が高く、「広い概念から狭い概念へ段階的に絞り込む」ことをより強く意識した書き方になっている。

- 初版攻略本（抜粋）: `experiments/wp-exp-20251113-4/books/0.txt`  
- 改訂版攻略本（抜粋）: `experiments/wp-exp-20251113-4/books/100.txt`

パッと見ただけでは、どちらが「強そうな攻略本」かを判断するのは難しい。Wikipediaゴルフという題材については、LLMが学習時点で既に多くの知識を持っているため、初版の時点でかなりそれらしいテキストが出ていることが影響していると考えられる。

次に、ポケモンWikiを対象としたポケモンWikiゴルフの攻略本を見てみる。最終版の攻略本（例: `experiments/poke-exp-20251113-3/books/100.txt`）には、

> 特に「(GO)」「(アニメ)」「(カードゲーム)」などの付記は、ゴールページの種類や関連性を特定する上で重要となる。

といった記述が含まれている。これは、ポケモンWiki特有のページ名の付け方に対応したテクニックであり、人間があらかじめ明示的に教えなくても、プレイ経験の中からLLMが自力で見つけ出した知識と言える。

このように、攻略本の自動生成・自動改訂という枠組みを通じて、「人間があまりプレイしたことのないルールやサイト構造」であっても、AIが試行錯誤を通じて有用なテクニックを言語化してくれる可能性があることが示唆された。

## まとめと今後の課題

本書では、Wikipediaゴルフを題材に「攻略本をAIに書かせる」試みを紹介した。LLMにゲームをプレイさせ、その結果をもとに攻略本を自動的に改訂するサイクルを構築することで、ある程度の性能向上が得られることを確認した。

日本語版Wikipediaだけでなく、ポケモンWikiやWikitravelといった特化型Wikiでも同様の手法を試したところ、いずれも初版と比べてわずかながら成功率が改善する傾向が見られた。特にポケモンWikiでは、ページ名の付記に着目したテクニックなど、そのWiki特有のルールを踏まえた攻略が自動的に言語化されている点が興味深い。

一方で、性能の伸び幅は決して劇的ではなく、特にWikipediaゴルフでは初版と改訂版の差は小さい。これは、攻略本の長さ制限が短く、あまり細かなケース分けや例示を書けないことや、LLMが既にWeb上の攻略記事を学習していることが影響していると考えられる。

また、LLMの呼び出しコストやレート制限も、実験規模を広げる上で無視できない制約となる。より大規模なプレイログを集めたり、複数のモデルを比較したりするには、コストと性能のトレードオフを慎重に設計する必要がある。

今後の課題としては、次のような方向性が考えられる。

- 攻略本の表現力を高めつつ、文字数やトークン数の制約をうまく満たすプロンプト設計の工夫  
- ゲームのルールや評価指標を変えた場合（別のWiki、別のリンク制約など）に、どの程度汎用的に応用できるかの検証  
- LLMによる「プレイ」と「解説」の役割分担を工夫し、プレイログから特徴的な失敗パターンを抽出してから攻略本にまとめるなど、より分析的なパイプラインの導入  
- 盤上ゲームやカードゲームなど、非テキスト中心のゲームに対しても、何らかの形で「攻略本自動生成」を適用できるかの探索

攻略本自動生成は、まだ小さな一歩にすぎないが、「AIにゲームの遊び方を説明させる」という発想は、教育やチュートリアル設計、UIガイドなど、さまざまな応用先を持つ可能性がある。読者自身も、身近なゲームやサービスを題材に、LLMに独自の攻略本を書かせてみてほしい。本書が、その第一歩の参考になれば幸いである。

